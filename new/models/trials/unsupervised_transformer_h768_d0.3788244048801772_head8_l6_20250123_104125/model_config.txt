Run Name: unsupervised_transformer_h768_d0.3788244048801772_head8_l6_20250123_104125
Hidden Size: 768
Number of Heads: 8
Number of Layers: 6
Dropout: 0.3788244048801772
Learning Rate: 0.00012975381369387435
Batch Size: 128

Training Results:
Best Pretrain Loss: 0.07672411060190622
Best Pretrain Epoch: 49
Best Finetune Loss: 0.2899994343932089
Best Finetune Epoch: 99
Test MSE: 0.3288227319717407
Test MAE: 0.3263281285762787
Test R2: 0.697519603752558
